"""
LLM Module - Káº¿t ná»‘i vá»›i local LLM server vÃ  database
"""

import json
import logging
from datetime import date
from typing import Any, Dict, List, Optional

from src.utils.http_session import get_session

# Load config (works both when running from src/ and repo root)
try:
    import config
except Exception:
    from src import config

logger = logging.getLogger(__name__)


class LocalLLMClient:
    """Client Ä‘á»ƒ káº¿t ná»‘i vá»›i local LLM server (LM Studio, Ollama, etc.)"""

    def __init__(self, base_url: str = "http://localhost:1234/v1", timeout: int = 120):
        """
        Initialize LLM client

        Args:
            base_url: Base URL cá»§a LLM server (OpenAI-compatible)
            timeout: Timeout cho requests (seconds), default 120s cho insights generation
        """
        self.base_url = base_url.rstrip("/")
        self.timeout = timeout
        self.headers = {"Content-Type": "application/json"}
        logger.info(f"Initialized LocalLLMClient with base_url: {self.base_url}")

    def test_connection(self) -> bool:
        """
        Test connection Ä‘áº¿n LLM server

        Returns:
            True náº¿u káº¿t ná»‘i thÃ nh cÃ´ng
        """
        try:
            session = get_session()
            response = session.get(f"{self.base_url}/models", headers=self.headers, timeout=5)
            if response.status_code == 200:
                models = response.json()
                logger.info(f"âœ“ Connected to LLM server. Available models: {models}")
                return True
            else:
                logger.warning(f"LLM server responded with status {response.status_code}")
                return False
        except Exception as e:
            logger.error(f"Failed to connect to LLM server: {e}")
            return False

    def chat_completion(
        self,
        messages: List[Dict[str, str]],
        model: str = "local-model",
        temperature: float = 0.1,
        max_tokens: int = 1000,
        timeout: Optional[int] = None,  # Allow override timeout per request
    ) -> Optional[str]:
        """
        Gá»­i chat completion request Ä‘áº¿n LLM

        Args:
            messages: List of message dicts with 'role' and 'content'
            model: Model name (tÃ¹y LLM server)
            temperature: Sampling temperature (0-1)
            max_tokens: Maximum tokens to generate
            timeout: Optional timeout override for this request (seconds)

        Returns:
            Generated text hoáº·c None náº¿u lá»—i
        """
        try:
            payload = {"model": model, "messages": messages, "temperature": temperature, "max_tokens": max_tokens}

            # Use per-request timeout if provided, else use default
            request_timeout = timeout if timeout is not None else self.timeout

            session = get_session()
            response = session.post(
                f"{self.base_url}/chat/completions", headers=self.headers, json=payload, timeout=request_timeout
            )

            if response.status_code == 200:
                result = response.json()
                content = result.get("choices", [{}])[0].get("message", {}).get("content", "")
                return content
            else:
                logger.error(f"LLM request failed: {response.status_code} - {response.text}")
                return None

        except Exception as e:
            logger.exception(f"Error in chat_completion: {e}")
            return None

    def parse_transaction_text(self, raw_text: str) -> Dict[str, Any]:
        """
        Parse Vietnamese transaction text thÃ nh structured data

        Args:
            raw_text: Raw transaction text

        Returns:
            Dictionary vá»›i transaction info hoáº·c {"raw": "Invalid"}
        """
        system_prompt = """Báº¡n lÃ  há»‡ thá»‘ng trÃ­ch xuáº¥t thÃ´ng tin giao dá»‹ch tÃ i chÃ­nh.
PhÃ¢n tÃ­ch text tiáº¿ng Viá»‡t vÃ  tráº£ vá» JSON vá»›i cÃ¡c trÆ°á»ng:
- merchant_name: TÃªn cá»­a hÃ ng/ngÆ°á»i nháº­n (string, dÃ¹ng "Payment" náº¿u khÃ´ng rÃµ)
- total_amount: Tá»•ng sá»‘ tiá»n (integer, khÃ´ng dáº¥u pháº©y)
- bill_date: NgÃ y giao dá»‹ch YYYY-MM-DD (string, dÃ¹ng null náº¿u khÃ´ng cÃ³)
- category_name: Danh má»¥c tá»« danh sÃ¡ch (string)
- category_type: 0 cho chi tiÃªu, 1 cho thu nháº­p (integer)
- note: MÃ´ táº£ ngáº¯n (string)

Danh má»¥c chi tiÃªu (0): Ä‚n uá»‘ng, Xe cá»™, Mua sáº¯m, Há»c táº­p, Y táº¿, Du lá»‹ch, Äiá»‡n, NÆ°á»›c, Internet,
ThuÃª nhÃ , Giáº£i trÃ­, ThÃº cÆ°ng, Dá»‹ch vá»¥, Sá»­a chá»¯a, QuÃ  táº·ng, Chi tiÃªu khÃ¡c
Danh má»¥c thu nháº­p (1): LÆ°Æ¡ng, Tiá»n lÃ£i Ä‘áº§u tÆ°, Tiá»n cho thuÃª nhÃ , Thu nháº­p khÃ¡c

Tráº£ vá» ONLY JSON, khÃ´ng cÃ³ text khÃ¡c."""

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"PhÃ¢n tÃ­ch giao dá»‹ch: {raw_text}"},
        ]

        response = self.chat_completion(messages, temperature=0.1, max_tokens=500)

        if not response:
            return {"raw": "Invalid"}

        try:
            # Strip markdown code blocks náº¿u cÃ³
            cleaned = response.strip()
            if cleaned.startswith("```json"):
                cleaned = cleaned[7:]
            if cleaned.startswith("```"):
                cleaned = cleaned[3:]
            if cleaned.endswith("```"):
                cleaned = cleaned[:-3]
            cleaned = cleaned.strip()

            data = json.loads(cleaned)

            # Validate vÃ  set defaults
            if not isinstance(data, dict) or data.get("total_amount") is None:
                return {"raw": "Invalid"}

            # Set user_id (sáº½ Ä‘Æ°á»£c override bá»Ÿi caller)
            data["user_id"] = 2

            # Set bill_date náº¿u khÃ´ng cÃ³
            if not data.get("bill_date"):
                data["bill_date"] = date.today().isoformat()

            return data

        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse LLM response as JSON: {e}")
            logger.error(f"Raw response: {response[:500]}")
            return {"raw": "Invalid"}
        except Exception as e:
            logger.exception(f"Error parsing transaction: {e}")
            return {"raw": "Invalid"}


class LLMDatabaseAgent:
    """Agent Ä‘á»ƒ query database báº±ng natural language"""

    def __init__(self, llm_client: LocalLLMClient, db_getter):
        """
        Initialize agent

        Args:
            llm_client: LocalLLMClient instance
            db_getter: Callable contextmanager that yields a DB connection (e.g., connect_to_heroku_db)
        """
        self.llm = llm_client
        self.db_getter = db_getter
        self.schema_info = self._load_schema()
        logger.info("Initialized LLMDatabaseAgent")

    def _load_schema(self) -> str:
        """Load database schema information"""
        schema = """
Database Schema:

Table: users
- user_id (serial, primary key)
- user_name (varchar, unique)

Table: bills
- bill_id (serial, primary key)
- bill_date (date)
- user_id (integer, foreign key -> users.user_id)
- merchant_name (varchar)
- category_name (varchar)
- total_amount (decimal)
- note (text)
- category_type (smallint) -- 0: chi tiÃªu, 1: thu nháº­p
"""
        return schema

    def natural_language_query(self, question: str) -> Dict[str, Any]:
        """
        Tráº£ lá»i cÃ¢u há»i vá» dá»¯ liá»‡u trong database

        Args:
            question: CÃ¢u há»i báº±ng tiáº¿ng Viá»‡t

        Returns:
            Dictionary vá»›i answer vÃ  data (náº¿u cÃ³)
        """
        system_prompt = f"""Báº¡n lÃ  database query assistant.
Schema:
{self.schema_info}

User sáº½ há»i vá» dá»¯ liá»‡u. Báº¡n cáº§n:
1. Táº¡o SQL query phÃ¹ há»£p (chá»‰ SELECT, khÃ´ng UPDATE/DELETE)
2. Tráº£ vá» JSON vá»›i format:
{{
  "sql": "SELECT ... FROM ...",
  "explanation": "Giáº£i thÃ­ch ngáº¯n vá» query"
}}

Chá»‰ tráº£ vá» JSON, khÃ´ng cÃ³ text khÃ¡c."""

        messages = [{"role": "system", "content": system_prompt}, {"role": "user", "content": question}]

        response = self.llm.chat_completion(messages, temperature=0.1, max_tokens=500)

        if not response:
            return {"success": False, "error": "LLM khÃ´ng tráº£ vá» response"}

        try:
            # Parse JSON response
            cleaned = response.strip()
            if cleaned.startswith("```json"):
                cleaned = cleaned[7:]
            if cleaned.startswith("```"):
                cleaned = cleaned[3:]
            if cleaned.endswith("```"):
                cleaned = cleaned[:-3]
            cleaned = cleaned.strip()

            result = json.loads(cleaned)
            sql = result.get("sql", "")
            explanation = result.get("explanation", "")

            if not sql:
                return {"success": False, "error": "KhÃ´ng táº¡o Ä‘Æ°á»£c SQL query"}

            # Validate SQL (security check)
            sql_upper = sql.upper()
            if any(keyword in sql_upper for keyword in ["DROP", "DELETE", "UPDATE", "INSERT", "ALTER", "CREATE"]):
                return {"success": False, "error": "Query khÃ´ng Ä‘Æ°á»£c phÃ©p (chá»‰ SELECT)"}

            # Execute query
            with self.db_getter() as conn:
                cursor = conn.cursor()
                cursor.execute(sql)
                rows = cursor.fetchall()
                columns = [desc[0] for desc in cursor.description] if cursor.description else []
                cursor.close()

            # Convert to list of dicts
            data = [dict(zip(columns, row)) for row in rows]

            return {"success": True, "sql": sql, "explanation": explanation, "data": data, "count": len(data)}

        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse LLM SQL response: {e}")
            return {"success": False, "error": f"KhÃ´ng parse Ä‘Æ°á»£c JSON: {e}"}
        except Exception as e:
            logger.exception(f"Error executing query: {e}")
            return {"success": False, "error": f"Lá»—i database: {str(e)}"}

    def get_spending_insights(self, user_id: int, days: int = 30) -> str:
        """
        Táº¡o insights vá» chi tiÃªu cá»§a user

        Args:
            user_id: User ID
            days: Sá»‘ ngÃ y Ä‘á»ƒ phÃ¢n tÃ­ch

        Returns:
            Text insights tá»« LLM
        """
        try:
            # Get spending data
            sql = f"""
            SELECT
                category_name,
                category_type,
                SUM(total_amount) as total,
                COUNT(*) as count
            FROM bills
            WHERE user_id = %s
              AND bill_date >= CURRENT_DATE - INTERVAL '{days} days'
            GROUP BY category_name, category_type
            ORDER BY total DESC;
            """

            with self.db_getter() as conn:
                cursor = conn.cursor()
                cursor.execute(sql, (user_id,))
                rows = cursor.fetchall()
                columns = [desc[0] for desc in cursor.description]
                cursor.close()

            if not rows:
                return f"KhÃ´ng cÃ³ dá»¯ liá»‡u chi tiÃªu trong {days} ngÃ y qua."

            # Format data for LLM
            data_text = f"Dá»¯ liá»‡u chi tiÃªu cá»§a user_id={user_id} trong {days} ngÃ y qua:\n\n"
            for row in rows:
                row_dict = dict(zip(columns, row))
                category_type = "Thu nháº­p" if row_dict["category_type"] == 1 else "Chi tiÃªu"
                data_text += (
                    f"- {row_dict['category_name']} ({category_type}): "
                    f"{row_dict['total']:,.0f} VND ({row_dict['count']} giao dá»‹ch)\n"
                )

            logger.info(f"Generating insights for {len(rows)} categories...")

            # Ask LLM for insights
            messages = [
                {
                    "role": "system",
                    "content": (
                        "Báº¡n lÃ  financial advisor. PhÃ¢n tÃ­ch dá»¯ liá»‡u chi tiÃªu vÃ  Ä‘Æ°a ra "
                        "insights ngáº¯n gá»n (3-5 cÃ¢u), lá»i khuyÃªn cá»¥ thá»ƒ. Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t."
                    ),
                },
                {"role": "user", "content": f"{data_text}\n\nHÃ£y phÃ¢n tÃ­ch ngáº¯n gá»n chi tiÃªu cá»§a tÃ´i."},
            ]

            # Use shorter max_tokens and higher temperature for insights
            insights = self.llm.chat_completion(
                messages,
                temperature=0.4,
                max_tokens=300,  # Reduced from 800 to speed up generation
                timeout=180,  # 3 minutes for insights (longer than default)
            )

            if insights:
                logger.info("Insights generated successfully")
                return insights
            else:
                logger.warning("LLM returned empty insights")
                return "KhÃ´ng thá»ƒ táº¡o insights lÃºc nÃ y."

        except Exception as e:
            logger.exception(f"Error getting insights: {e}")
            return f"Lá»—i khi táº¡o insights: {str(e)}"

    def get_quick_summary(self, user_id: int, days: int = 30) -> str:
        """
        Táº¡o summary nhanh vá» chi tiÃªu (khÃ´ng cáº§n LLM)

        Args:
            user_id: User ID
            days: Sá»‘ ngÃ y Ä‘á»ƒ phÃ¢n tÃ­ch

        Returns:
            Text summary
        """
        try:
            sql = f"""
            SELECT
                category_name,
                category_type,
                SUM(total_amount) as total,
                COUNT(*) as count
            FROM bills
            WHERE user_id = %s
              AND bill_date >= CURRENT_DATE - INTERVAL '{days} days'
            GROUP BY category_name, category_type
            ORDER BY total DESC
            LIMIT 5;
            """

            with self.db_getter() as conn:
                cursor = conn.cursor()
                cursor.execute(sql, (user_id,))
                rows = cursor.fetchall()
                columns = [desc[0] for desc in cursor.description]
                cursor.close()

            if not rows:
                return f"KhÃ´ng cÃ³ dá»¯ liá»‡u chi tiÃªu trong {days} ngÃ y qua."

            # Build summary
            summary = f"ðŸ“Š TÃ³m táº¯t {days} ngÃ y qua:\n\n"

            total_expense = 0
            total_income = 0

            for row in rows:
                row_dict = dict(zip(columns, row))
                amount = float(row_dict["total"])

                if row_dict["category_type"] == 0:  # Chi tiÃªu
                    total_expense += amount
                    summary += f"ðŸ’° {row_dict['category_name']}: {amount:,.0f} VND ({row_dict['count']} giao dá»‹ch)\n"
                else:  # Thu nháº­p
                    total_income += amount
                    summary += f"ðŸ’µ {row_dict['category_name']}: {amount:,.0f} VND ({row_dict['count']} giao dá»‹ch)\n"

            summary += f"\nðŸ“ˆ Tá»•ng thu nháº­p: {total_income:,.0f} VND"
            summary += f"\nðŸ“‰ Tá»•ng chi tiÃªu: {total_expense:,.0f} VND"

            balance = total_income - total_expense
            if balance > 0:
                summary += f"\nâœ… CÃ²n láº¡i: +{balance:,.0f} VND"
            else:
                summary += f"\nâš ï¸  VÆ°á»£t chi: {balance:,.0f} VND"

            return summary

        except Exception as e:
            logger.exception(f"Error getting summary: {e}")
            return f"Lá»—i khi táº¡o summary: {str(e)}"


def create_llm_client(base_url: str = "http://localhost:1234/v1", timeout: Optional[int] = None) -> LocalLLMClient:
    """
    Factory function Ä‘á»ƒ táº¡o LLM client

    Args:
        base_url: URL cá»§a local LLM server
        timeout: Timeout cho requests (seconds)

    Returns:
        LocalLLMClient instance
    """
    if timeout is None:
        timeout = getattr(config, "LLM_DEFAULT_TIMEOUT", 120)
    return LocalLLMClient(base_url=base_url, timeout=timeout)


def create_llm_db_agent(base_url: str = "http://localhost:1234/v1", timeout: int = 120) -> Optional[LLMDatabaseAgent]:
    """
    Factory function Ä‘á»ƒ táº¡o LLM Database Agent

    Args:
        base_url: URL cá»§a local LLM server
        timeout: Timeout cho requests (seconds)

    Returns:
        LLMDatabaseAgent instance hoáº·c None náº¿u khÃ´ng connect Ä‘Æ°á»£c DB
    """
    try:
        from database.database import connect_to_heroku_db

        llm_client = LocalLLMClient(base_url=base_url, timeout=timeout)

        # Pass the contextmanager function into the agent so it can get pooled
        # connections for each operation.
        return LLMDatabaseAgent(llm_client, connect_to_heroku_db)

    except Exception as e:
        logger.exception(f"Error creating LLMDatabaseAgent: {e}")
        return None
